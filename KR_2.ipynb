{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "1. Опишите теоретическую модель градиентного бустинга\n",
    "\n",
    "2. Напишите следующий год: сгенерируйте данные в виде набора точек; постройте регрессионную модель;\n",
    "оцените её точность; визуализируйте результат.\n",
    "\n",
    "3. Опишите метрику для проверки качества алгоритмов классификации.\n",
    "\n",
    "4. Опишите технологию масштабирования признаков. Привидите примеры."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 Номер\n",
    "\n",
    "1) Создаем \"базовую\" модель, тренируем ее\n",
    "2) Вычисляем ошибку, берем ее за инпут\n",
    "3) Строим вторю модель \"ансамбля\" так, чтобы она училась предсказывать и минимизировать именно\n",
    "ошибку\n",
    "4) Повторяем так до тех пор пока не надоест"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 Номер \n",
    "\n",
    "Это буквально дз №3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 Номер\n",
    "``` python\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "# все верные предсказания / все предсказания\n",
    "# сама по себе не очень полезна, особенно если датасет \"странный\", но позволяет быстро определить\n",
    "# насколько все плохо  \n",
    "print('Confusion Matrix:')\n",
    "print(cm)\n",
    "print(\"True Negative || False Positive\")\n",
    "print(\"False Negative || True Positive\")\n",
    "# Самая информативная метрика, от того и сложно читаемая\n",
    "#  |                  | Predicted Positive | Predicted Negative |\n",
    "#  |------------------|--------------------|--------------------|\n",
    "#  | Actual Positive  | True Positive (TP) | False Negative (FN)|\n",
    "#  | Actual Negative  | False Positive (FP)| True Negative (TN) |\n",
    "# Показывает насколько хорошо модель справилась с классификацией. Вообще матрица может быть любого\n",
    "# \"квадратного\" размера, но в таком случае ее исследовать становится тяжелее и тяжелее, поэтому \n",
    "# рассмотрим 2х2. ТР это когда значение = 1 и нейронка сказала что значение = 1. ТN соответственно \n",
    "# наоборот. FN и FP это когда нейронка ошибается в ту или иную сторону. По этой матрице можно \n",
    "# понять что вообще нейронка научилась делать. К примеру если вы изначально хотели научить ее \n",
    "# различать 10 классов, но так вышло что она может с хорошей точностью определять лишь 1, то \n",
    "# это будет заметно только в этой матрице, но не в accuracy \n",
    "\n",
    "\n",
    "print(f\"Precision: {report['precision']:.4f}\")\n",
    "# это отношения количества реальных 1 к сумме всех предсказанных едениц TP/(TP+FP). Собственно по\n",
    "# этой метрике можно как раз увидеть что 1 из 10 классов предсказывается очень хорошо, тогда как \n",
    "# общая точность плоха \n",
    "print(f\"Recall: {report['recall']:.4f}\")\n",
    "# а тут отношение количества реальных едениц к сумме из предсказанных едениц и \"недопредсказанных\"\n",
    "# едениц. Это нужно когда нам очень важно чтобы минимальное количество едениц осталось нулями \n",
    "\n",
    "print(f\"F1-Score: {report['f1-score']:.4f}\")\n",
    "# а f1 как раз является средним гармоническим между присижном и реколлом, он нужен чтобы модель не \n",
    "# могла по хитрому нас обдурить, например всегда выбирая один из классов она максимизирует реколл\n",
    "# или перетренировавшись на один из классов чтобы максимизировать присижн \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "1)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
